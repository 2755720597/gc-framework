## 消息队列
### 1. 消息队列有哪些使用场景。
异步处理，应用解耦，流量削锋和消息通讯四个场景

eg:https://www.cnblogs.com/ruiati/p/6649868.html

### 2. 消息中间件如何解决消息丢失问题？
* Kafka的可靠性传输 -->Kafka出现丢失的情况

![](https://img-blog.csdnimg.cn/20190907214127860.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3plbmdkb25nd2Vu,size_16,color_FFFFFF,t_70)

2.1.1 消费者端丢失消息

丢失的原因：

   唯一可能导致消费者弄丢数据的情况，就是说，你消费到了这个消息，然后消费者那边自动提交了 offset，让 Kafka 以为你已经消费了这个消息，但其实你才刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。

解决的办法：

   这不是跟 RabbitMQ 差不多吗，大家都知道 Kafka 会自动提交 offset，那么只要**关闭自动提交 offset**，在处理完之后自己手动提交 offset，就可以保证数据不会丢。但是此时确实还是**可能会有重复消费**，比如你刚处理完，还没提交 offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了。

注意：生产环境碰到的一个问题，就是说我们的 Kafka 消费者消费到了数据之后是写到一个内存的 queue 里先缓冲一下，结果有的时候，你刚把消息写入内存 queue，然后消费者会自动提交 offset。然后此时我们重启了系统，就会导致内存 queue 里还没来得及处理的数据就丢失了。

2.1.2 Kafka丢失消息

丢失的原因：

   我们知道，在Kafka的高可用集群环境中，生产者和消费者都是跟leader节点交流的，leader接收到生产者的消息之后，会同步到其他的follower中。如果leader在接收到消息之后，同步消息到follower的操作还没完成，此时leader就宕机了。那么就会从follower中选出一个新的leader，而这个leader中就会缺少没有同步的那些数据，消费者也就无法消费到，这就造成了消息的丢失。

解决的办法：

  需要设置四个参数，具体解释如下：

- 给 topic 设置 replication.factor 参数：这个值必须大于 1，要求每个 partition 必须有至少 2 个副本。
- 在 Kafka 服务端设置 min.insync.replicas 参数：这个值必须大于 1，这个是要求一个 leader 至少感知到有至少一个 follower 还跟自己保持联系，没掉队，这样才能确保 leader 挂了还有一个 follower 吧。
- 在 producer 端设置 acks=all：这个是要求每条数据，必须是**写入所有 replica 之后，才能认为是写成功了。**
- 在 producer 端设置 retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求**一旦写入失败，就无限重试**，卡在这里了。

2.1.3 生成者丢失消息
  
其实生成者丢失消息跟RabbitMQ是一样的，生产者把消息发送到了Kafka，但是Kafka还没保存到消息，就宕机了，导致了消息的丢失。但是如果我们为了不让Kafka丢失消息，进行了上面这样4个参数的配置，那么就不会出现生产者丢失消息了。因为消息一定要存到了副本上才会证明消息发送成功，否则生产者会一直重试。

eg:https://blog.csdn.net/zengdongwen/article/details/100587102

https://www.jianshu.com/p/4491cba335d1

### 3. 谈谈消息的重发，补充策略。
https://blog.csdn.net/riemann_/article/details/101001361

### 4. 如何保证消息的顺序性。

https://www.jianshu.com/p/8a5630e2c317

### 5. 怎么利用mq实现最终一致性？

https://www.jianshu.com/p/eb571e4065ec

### 6. kafka 和其他消息队列的区别，kafka 主从同步怎么实现？
https://blog.csdn.net/m0_46109609/article/details/110441883

### 7. MQ的连接是线程安全的吗，你们公司的MQ服务架构怎样的。

### 8. kafka吞吐量高的原因。
（1）顺序读写：基于磁盘的随机读写确实很慢，但磁盘的顺序读写性能却很高，一些情况下磁盘顺序读写性能甚至要高于内存随机读写。（Kafka的message是不断追加到本地磁盘文件末尾的，而不是随机的写入，这使得Kafka写入吞吐量得到了显著提升 。）

（2）Page Cache:为了优化读写性能，kafka利用了操作系统本身的page cache,就是利用操作系统自身的内存而不是JVM空间内存，这样做的好处是：

- 1：避免Object消耗：如果是使用java堆，java对象的内存消耗比较大，通常是所存储数据的两倍甚至更多。

- 2：避免GC问题：随着JVM中数据不断增多，垃圾回收将会变得复杂与缓慢，使用系统缓存就不会存在GC问题。

通过操作系统的page cache,kafka的读写操作基本上是基于内存的，读写速度得到了极大的提升。

（3）零拷贝:（不使用的时候，数据在内核空间和用户空间之间穿梭了两次），使用零拷贝技术后避免了这种拷贝。通过这种 “零拷贝” 的机制，Page Cache 结合 sendfile 方法，Kafka消费端的性能也大幅提升。这也是为什么有时候消费端在不断消费数据时，我们并没有看到磁盘io比较高，此刻正是操作系统缓存在提供数据。

（4）分区分段+索引：topic 中的数据是按照一个一个的partition即分区存储到不同broker节点的，每个partition对应了操作系统上的一个文件夹，partition实际上又是按照segment分段存储的，这也非常符合分布式系统分区分桶的设计思想。kafka的message消息实际上是分布式存储在一个一个segment中的，每次文件操作也是直接操作的segment。为了进一步的查询优化，kafka又默认为分段后的数据文件建立了索引文件，就是文件系统上的.index文件.这种分区分段+索引的设计，不仅提升了数据读取的效率，同时也提高了数据处理的并行度。

（5）批量读写：Kafka数据读写也是批量的而不是单条的。在向Kafka写入数据时，可以启用批次写入，这样可以避免在网络上频繁传输单个消息带来的延迟和带宽开销。假设网络带宽为10MB/S，一次性传输10MB的消息比传输1KB的消息10000万次显然要快得多。

（6）批量压缩：

在很多情况下，系统的瓶颈不是CPU或磁盘，而是网络IO，对于需要在广域网上的数据中心之间发送消息的数据流水线尤其如此。进行数据压缩会消耗少量的CPU资源,不过对于kafka而言,网络IO更应该需要考虑。

- 如果每个消息都压缩，但是压缩率相对很低，所以Kafka使用了批量压缩，即将多个消息一起压缩而不是单个消息压缩
- Kafka允许使用递归的消息集合，批量的消息可以通过压缩的形式传输并且在日志中也可以保持压缩格式，直到被消费者解压缩
- Kafka支持多种压缩协议，包括Gzip和Snappy压缩协议

Kafka速度的秘诀在于，它把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO损耗，通过mmap提高I/O速度，写入数据的时候由于单个Partion是末尾添加所以速度最优；读取数据的时候配合sendfile直接暴力输出。

https://www.cnblogs.com/18800105616a/p/13863254.html


### 9. rabbitmq如何实现集群高可用？

### 10. 使用kafka有没有遇到什么问题，怎么解决的？
- 1）、指定了 key,多个消费者的话只有一个可以消费。 ---》分区路由算法
- 2）、消息发送至少含有一个leader、一个follower，否则存在数据丢失情况
- 3）、生产者存在重复发送消息的情况  ----》配置幂等性处理
- 4）、消费者重复消费    ----》手动提交 | 幂等性操作



### 11. MQ有可能发生重复消费，如何避免，如何做到幂等？
保证幂等性(重复消费)

要保证消息的幂等性，这个要结合业务的类型来进行处理。下面提供几个思路供参考：

- （1）、可在内存中维护一个set，只要从消息队列里面获取到一个消息，先查询这个消息在不在set里面，如果在表示已消费过，直接丢弃；如果不在，则在消费后将其加入set当中。
- （2）、如何要写数据库，可以拿唯一键先去数据库查询一下，如果不存在在写，如果存在直接更新或者丢弃消息。
- （3）、如果是写redis那没有问题，每次都是set，天然的幂等性。
- （4）、让生产者发送消息时，每条消息加一个全局的唯一id，然后消费时，将该id保存到redis里面。消费时先去redis里面查一下有么有，没有再消费。
- （5）、数据库操作可以设置唯一键，防止重复数据的插入，这样插入只会报错而不会插入重复数据。

https://www.jianshu.com/p/172295e2e978?hmsr=toutiao.io

### 12. MQ的消息延迟了怎么处理，消息可以设置过期时间么，过期了你们一般怎么处理？
https://www.cnblogs.com/youcoding/p/14205149.html


### 13. rabbitmq 有几种广播类型？
direct（默认方式）：最基础最简单的模式，发送方把消息发送给订阅方，如果有多个订阅者，默认采取轮询的方式进行消息发送。

headers：与 direct 类似，只是性能很差，此类型几乎用不到。

fanout：分发模式，把消费分发给所有订阅者。

topic：匹配订阅模式，使用正则匹配到消息队列，能匹配到的都能接收到。

https://blog.csdn.net/YOUYOU0710/article/details/109704501

### 14. 使用 kafka 集群需要注意什么？
集群的数量不是越多越好，最好不要超过 7 个，因为节点越多，消息复制需要的时间就越长，整个群组的吞吐量就越低。 集群数量最好是单数，因为超过一半故障集群就不能用了，设置为单数容错率更高。


### 15. 为什么使用消息队列？有什么用？ 16. 消息队列有什么优点和缺点？ 17. Kafka、ActiveMQ、RabbitMQ、RocketMQ 都有什么区别，以及适合哪些场景？
https://www.cnblogs.com/terry-love/p/11492397.html

### 18. MQ能否保证消息必达，即消息的可靠性
https://www.jianshu.com/p/4491cba335d1

### 19. 大量消息在MQ里长时间积压，该如何解决？ 20. MQ消息过期失效怎么办？
https://www.cnblogs.com/youcoding/p/14205149.html

### 21. kafka可以脱离zookeeper单独使用吗？为什么？
https://www.yukx.com/jing/article/details/1909.html

https://blog.csdn.net/m0_46552679/article/details/116163458

### 22. kafka 的分区策略有哪些？
* kafka生产者的分区策略

1 随机策略

2 轮询策略（kafka默认）

3 按照key的分区策略，Key-ordering

4 自定义分区策略，需要实现 org.apache.kafka.clients.producer.Partitioner 接口中的分区方法

https://www.cnblogs.com/lincf/p/11985026.html

* kafka消费者的分区消费策略

1 Range  Startegy（根据范围消费）

2 round-robin 消费者按照hash分区

https://www.jianshu.com/p/99b4187a994d

### 23. kafka 有几种数据保留策略？
kafka 有两种数据保存策略：按照过期时间保留和按照存储的消息大小保留。

### 24. RabbitMQ 中的 broker 是指什么？cluster 又是指什么？
broker 是指一个或多个 erlang node 的逻辑分组，且 node 上运行着 RabbitMQ 应用程序。

cluster 是在 broker 的基础之上，增加了 node 之间共享元数据的约束

**概念**

Broker：消息队列服务器实体

exchange：消息交换机，指定消息规则，处理消息和队列之间的关系
- Exchange是属于Vhost的。同一个Vhost不能有重复的Exchange名称。
- Exchange的绑定功能，可以绑定queue，也可以绑定Exchange

queue：队列载体，消息投入队列中

binding：绑定，把exchange和queue按照路由规则绑定起来

Routing Key：路由关键字。exchange根据这个进行消息投递

vhost：虚拟消息服务器，每个RabbitMQ服务器都能够创建虚拟消息服务器。
- Vhost之间相互完全隔离，不同Vhost之间无法共享Exchange和Queue。因此Vhost之间数据无法共享和分享。
- RabbitMQ的Vhost主要是用来划分不同业务模块。不同业务模块之间没有信息交互。
- vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部均含有独立的 queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到 vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段

producer：生产者，投递消息的程序

consumer：消费者，接受消息的程序

channel：信道（重要概念），打开信道才能进行通信，一个channel代码一个会话任务

channel 是真实 TCP 连接之上的虚拟连接

https://www.cnblogs.com/frankltf/p/10373524.html
### 25. Kafka 消息是采用 Pull 模式，还是 Push 模式？
Kafka最初考虑的问题是，customer应该从brokes拉取消息还是brokers将消息推送到consumer，也就是pull还push。
在这方面，Kafka遵循了一种大部分消息系统共同的传统的设计：**producer将消息推送到broker，consumer从broker拉取消息。**

一些消息系统比如Scribe和Apache Flume采用了push模式，将消息推送到下游的consumer。这样做有好处也有坏处：
由broker决定消息推送的速率，对于不同消费速率的consumer就不太好处理了。消息系统都致力于让consumer以最大的速率最快速的消费消息，
但不幸的是，push模式下，当broker推送的速率远大于consumer消费的速率时，consumer恐怕就要崩溃了。

最终Kafka还是选取了传统的pull模式。Pull模式的另外一个好处是consumer可以否批量的**自主决定是从broker拉取数据**。

Push模式必须在不知道下游consumer消费能力和消费策略的情况下决定是立即推送每条消息还是缓存之后批量推送。
如果为了避免consumer崩溃而采用较低的推送速率，将可能导致一次只推送较少的消息而造成浪费。

Pull模式下，consumer就可以根据自己的消费能力去决定这些策略。Pull有个缺点是，如果broker没有可供消费的消息，
将导致consumer不断在循环中轮询，直到新消息到t达。

为了避免这点，Kafka有个参数可以让consumer阻塞知道新消息到达(当然也可以阻塞知道消息的数量达到某个特定的量这样就可以批量发

https://www.cnblogs.com/programb/p/12906702.html
### 26. RabbitMQ 有哪些重要组件
1、Server：Broker，接受client连接，实现AMQP实体服务　　

2、Connection：应用程序和Broker的网络连接　　

3、Channel：网络信道，读写都是在Channel中进行（NIO的概念），包括对MQ进行的一些操作（例如clear queue等）都是在Channel中进行，客户端可建立多个Channel，每个Channel代表一个会话任务　　

4、Message：由properties（有消息优先级、延迟等特性）和Body（消息内容）组成　　

5、Virtual host：用于消息隔离（类似Redis 16个db这种概念），最上层的消息路由，一个包含若干Exchange和Queue，同一个里面Exchange和Queue的名称不能存在相同的。　　

6、Exchange：Routing and Filter　　

7、Binding：把Exchange和Queue进行Binding　　

8、Routing key：路由规则　　

9、Queue：物理上存储消息

![](https://img2018.cnblogs.com/common/1472588/202002/1472588-20200204164526349-1998760003.png)

### 27. 如何确保消息接收方消费了消息？
* **发送方确认模式**

将信道设置成confirm 模式（发送方确认模式）， 则所有在信道上发布的消息都会被指派一个唯一的ID。

一旦消息被投递到目的队列后，或者消息被写入磁盘后（可持久化的消息）， 信道会发送一个确认给生产者（包含消息唯一ID）。

如果RabbitMQ 发生内部错误从而导致消息丢失，会发送一条nack（notacknowledged，未确认）消息。

发送方确认模式是异步的，生产者应用程序在等待确认的同时， 可以继续发送消息。当确认消息到达生产者应用程序，生产者应用程序的回调方法就会被触发来处理确认消息。

* **接收方确认机制**

消费者接收每一条消息后都必须进行确认（消息接收和消息确认是两个不同操作） 。只有消费者确认了消息， 
RabbitMQ 才能安全地把消息从队列中删除。这里并没有用到超时机制， 
RabbitMQ 仅通过Consumer 的连接中断来确认是否需要重新发送消息。也就是说，只要连接不中断， 
RabbitMQ 给了Consumer 足够长的时间来处理消息。保证数据的最终一致性；

下面罗列几种特殊情况

如果消费者接收到消息，在确认之前断开了连接或取消订阅，RabbitMQ 会认为消息没有被分发，然后重新分发给下一个订阅的消费者。（ 可能存在消息重复消费的隐患，需要去重）

如果消费者接收到消息却没有确认消息， 连接也未断开，则RabbitMQ 认为该消费者繁忙，将不会给该消费者分发更多的消息。

https://blog.csdn.net/siyuanwai/article/details/119451108
### 28. 消息基于什么传输？
由于TCP连接的创建和销毁开销较大，且并发数受系统资源限制，会造成性能瓶颈。RabbitMQ使用信道的方式来传输数据。channel是建立在真实的TCP连接内的虚拟连接，且每条TCP连接上的信道数量没有限制
## 29. 消息怎么路由？
消息提供方->路由->一至多个队列消息发布到交换器时，消息将拥有一个路由键（routing key），在消息创建时设定。通过队列路由键，可以把队列绑定到交换器上。消息到达交换器后，RabbitMQ 会将消息的路由键与队列的路由键进行匹配（针对不同的交换器有不同的路由规则）；

常用的交换器主要分为一下三种：

fanout：如果交换器收到消息，将会广播到所有绑定的队列上

direct：如果路由键完全匹配，消息就被投递到相应的队列

topic：可以使来自不同源头的消息能够到达同一个队列。使用 topic 交换器时，可以使用通配符

https://www.cnblogs.com/programb/p/12911715.html
### 30. 消息如何分发？
若该队列至少有一个消费者订阅，消息将以循环（round-robin）的方式发送给消费者。每条消息只会分发给一个订阅的消费者（前提是消费者能够正常处理消息并进行确认）。通过路由可实现多消费的功能.

https://www.cnblogs.com/programb/p/12911713.html

kafka 可以看分区策略，如  22. kafka 的分区策略有哪些？
